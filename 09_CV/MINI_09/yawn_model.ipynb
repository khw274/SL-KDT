{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5fb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d888269",
   "metadata": {},
   "source": [
    "#### [머신러닝(CV) 미니 프로젝트]\n",
    "- 운전자 부주의 분석\n",
    "- 현우 : 운전자 하품 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176cc62a",
   "metadata": {},
   "source": [
    "[0] img → csv <HR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e43af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img → csv\n",
    "# from img_to_csv import *\n",
    "\n",
    "# preprocess_images_to_csv('./data/img/no_yawn',\n",
    "#                          './data/csv',\n",
    "#                          'yawn',\n",
    "#                          'no_yawn'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6cb9e",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 사용자 정의 함수 로딩<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6cd32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [1-1] 모듈 로딩\n",
    "# -------------------------------------------------------------------------------------\n",
    "# 기본\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# 전처리 관련\n",
    "import numpy as np\n",
    "\n",
    "# ML학습 관련\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "# ML 데이터셋 및 전처리 관련\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ML CV, Pipeline 관련 \n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "# ML 성능지표 관련\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# ML 모델 저장\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e07eb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [1-2] 사용자 정의 함수 (전처리 및 데이터 로딩)\n",
    "# -------------------------------------------------------------------------------------\n",
    "DATA_DIR = \"./data\"\n",
    "CLASSES = [\"no_yawn\", \"yawn\"]  # label 0, 1\n",
    "IMG_SIZE = (64, 64)\n",
    "\n",
    "# Haar face detector\n",
    "face_cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def extract_hog(gray_64):\n",
    "    hog = cv2.HOGDescriptor(\n",
    "        _winSize=IMG_SIZE,\n",
    "        _blockSize=(16,16),\n",
    "        _blockStride=(8,8),\n",
    "        _cellSize=(8,8),\n",
    "        _nbins=9\n",
    "    )\n",
    "    return hog.compute(gray_64).flatten()\n",
    "\n",
    "def detect_largest_face(gray):\n",
    "    \n",
    "    # 얼굴 여러개면 가장 큰 것 1개만 사용\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(40,40))\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    x,y,w,h = max(faces, key=lambda b: b[2]*b[3])\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def img_to_feature(img_bgr):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    box = detect_largest_face(gray)\n",
    "    if box is None:\n",
    "        return None\n",
    "    x,y,w,h = box\n",
    "    face = gray[y:y+h, x:x+w]\n",
    "    face = cv2.resize(face, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    feat = extract_hog(face)\n",
    "    return feat\n",
    "\n",
    "def load_dataset():\n",
    "    x, y = [], []\n",
    "    for label, cls in enumerate(CLASSES):\n",
    "        paths = glob.glob(os.path.join(DATA_DIR, cls, \"*\"))\n",
    "        for p in paths:\n",
    "            img = cv2.imread(p)\n",
    "            if img is None:\n",
    "                continue\n",
    "            feat = img_to_feature(img)\n",
    "            if feat is None:\n",
    "                continue\n",
    "            x.append(feat)\n",
    "            y.append(label)\n",
    "\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da11d3f",
   "metadata": {},
   "source": [
    "[3] 데이터 로딩 및 피쳐와 타겟 분리 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74635d1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# [3-1] 데이터 준비\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataAR = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(dataAR)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m feat = \u001b[43mimg_to_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mimg_to_feature\u001b[39m\u001b[34m(img_bgr)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimg_to_feature\u001b[39m(img_bgr):\n\u001b[32m     31\u001b[39m     gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     box = \u001b[43mdetect_largest_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     34\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mdetect_largest_face\u001b[39m\u001b[34m(gray)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_largest_face\u001b[39m(gray):\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# 얼굴 여러개면 가장 큰 것 1개만 사용\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     faces = \u001b[43mface_cascade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminSize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces) == \u001b[32m0\u001b[39m:\n\u001b[32m     26\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [3-1] 데이터 준비\n",
    "# -------------------------------------------------------------------------------------\n",
    "dataAR = load_dataset()\n",
    "print(dataAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 데이터 shape: featureDF(826, 1764), targetSR(826,)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# [3-1] 피쳐, 타겟 설정\n",
    "# --------------------------------------------------------------\n",
    "featureDF, targetSR = load_dataset()\n",
    "\n",
    "print(f\"\\n최종 데이터 shape: featureDF{featureDF.shape}, targetSR{targetSR.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d1168",
   "metadata": {},
   "source": [
    "[4] 훈련용(feature) / 테스트용(target) 분리 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41efcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [4-1] 데이터 분리\n",
    "# -------------------------------------------------------------------------------------\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    featureDF,\n",
    "    targetSR,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=targetSR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a12a86c",
   "metadata": {},
   "source": [
    "[5] all_estimators <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027125fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★ BEST update: AdaBoostClassifier acc=0.8373\n",
      "★ BEST update: BaggingClassifier acc=0.8735\n",
      "★ BEST update: CalibratedClassifierCV acc=0.8855\n",
      "★ BEST update: ExtraTreesClassifier acc=0.9036\n",
      "★ BEST update: NuSVC acc=0.9277\n",
      "\n",
      "=== BEST RESULT ===\n",
      "Model: NuSVC\n",
      "Accuracy: 0.927710843373494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no_yawn       0.91      0.95      0.93        82\n",
      "        yawn       0.95      0.90      0.93        84\n",
      "\n",
      "    accuracy                           0.93       166\n",
      "   macro avg       0.93      0.93      0.93       166\n",
      "weighted avg       0.93      0.93      0.93       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [5-1] 모델 순회 및 교차 검증 (All Estimators)\n",
    "# -------------------------------------------------------------------------------------\n",
    "estimators = all_estimators(type_filter=\"classifier\")\n",
    "best = {\"name\": None, \"model\": None, \"acc\": -1}\n",
    "\n",
    "for name, Est in estimators:\n",
    "    try:\n",
    "        model = Est()\n",
    "        if not isinstance(model, ClassifierMixin):\n",
    "            continue\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", model),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(x_train, y_train)\n",
    "        pred = pipe.predict(x_test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "\n",
    "        if acc > best[\"acc\"]:\n",
    "            best.update({\"name\": name, \"model\": pipe, \"acc\": acc})\n",
    "            print(f\"★ BEST update: {name} acc={acc:.4f}\")\n",
    "\n",
    "    except Exception:\n",
    "        # all_estimators는 실패하는 모델이 꽤 있어서 그냥 스킵\n",
    "        continue\n",
    "\n",
    "if best[\"model\"] is None:\n",
    "    raise RuntimeError(\"학습 가능한 모델을 찾지 못함\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# [5-2] 결과 정리 및 최적 모델 선정\n",
    "# -------------------------------------------------------------------------------------\n",
    "print(\"\\n=== BEST RESULT ===\")\n",
    "print(\"Model:\", best[\"name\"])\n",
    "print(\"Accuracy:\", best[\"acc\"])\n",
    "print(classification_report(y_test, best[\"model\"].predict(x_test), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8f6f7",
   "metadata": {},
   "source": [
    "[6] 최적 모델 저장 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b924874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved -> best_yawn_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [6] 결과 정리 및 최적 모델 선정\n",
    "# -------------------------------------------------------------------------------------\n",
    "joblib.dump(best[\"model\"], \"best_yawn_model.joblib\")\n",
    "print(\"\\nSaved -> best_yawn_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_CV311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
