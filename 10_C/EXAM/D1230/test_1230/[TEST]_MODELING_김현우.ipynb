{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1392326e",
   "metadata": {},
   "source": [
    "##### 【 UCI Adult Income Dataset 】<hr>\n",
    "\n",
    "- 데이터 개요\n",
    "    * 특성: 수치형 + 범주형 혼합\n",
    "    * 크기: 약 4만 행 (샘플링 가능)\n",
    "    * 파일: adult.csv\n",
    "\n",
    "- 모델 목표\n",
    "    * 개인의 인구통계/직업 정보를 바탕으로 연소득이 50,000달러 초과인지 여부 예측\n",
    "\n",
    "- 컬럼 설명\n",
    "    * class 연소득이 50K 초과(>50K)인지, 이하(<=50K)인지를 나타내는 타깃 레이블\n",
    "    * age\t나이\n",
    "    * sex\t성별 (Male / Female)\n",
    "    * education-num\t교육 수준을 숫자로 표현한 값\n",
    "    * workclass\t고용 형태 (Private, Self-emp, Government 등)\n",
    "    * occupation\t직업 종류\n",
    "    * hours-per-week\t주당 근무 시간\n",
    "    * capital-gain\t자본 이득 (주식, 투자 수익 등)\n",
    "    * capital-loss\t자본 손실\n",
    "    * marital-status\t결혼 상태\n",
    "    * relationship\t가구 내 관계 (Husband, Wife, Not-in-family 등)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f262216",
   "metadata": {},
   "source": [
    "\n",
    "### 평가 기준\n",
    "- 전체 모델 학습 프로세스 적용 여부가 중요함!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0871ab",
   "metadata": {},
   "source": [
    "[0] 필요한 컬럼 선정 <hr>\n",
    "- 인구 통계와 직업 정보를 기반 \n",
    "    - -> target은 class 컬럼\n",
    "    - -> native_country는 모두 미국으로 추정돼서 삭제\n",
    "    - -> hours-per-week: 주당 근무 시간은 근무시간이 늘면 당연히 소득도 올라간다고 생각 -> 결과를 학습하는 것이 아닌가? 삭제하기로 결정\n",
    "    - -> race : 인종 차별적 요소 존재해서 삭제\n",
    "    - -> fnlwgt : 무슨 컬럼인지 몰라서 삭제\n",
    "    - -> education-num : 각각 컬럼 값들의 순서를 몰라서 삭제\n",
    "    - -> education : 설명에 없어서 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e709c",
   "metadata": {},
   "source": [
    "[1] 모듈 및 데이터 로딩 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b3b110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass      marital-status         occupation relationship     sex  \\\n",
       "0   25    Private       Never-married  Machine-op-inspct    Own-child    Male   \n",
       "1   38    Private  Married-civ-spouse    Farming-fishing      Husband    Male   \n",
       "2   28  Local-gov  Married-civ-spouse    Protective-serv      Husband    Male   \n",
       "3   44    Private  Married-civ-spouse  Machine-op-inspct      Husband    Male   \n",
       "4   18        NaN       Never-married                NaN    Own-child  Female   \n",
       "\n",
       "   capital-gain  capital-loss  class  \n",
       "0             0             0  <=50K  \n",
       "1             0             0  <=50K  \n",
       "2             0             0   >50K  \n",
       "3          7688             0   >50K  \n",
       "4             0             0  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# [1-1] 모듈 로딩\n",
    "# ==================================================================\n",
    "\n",
    "# 전처리 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib\n",
    "\n",
    "# ML 학습\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ML 모델\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# ML 전처리\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ML 성능평가\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "# [1-2] 데이터 준비 \n",
    "# ==================================================================\n",
    "\n",
    "FILE_NAME = './adult.csv'\n",
    "dataDF = pd.read_csv(FILE_NAME)\n",
    "dataDF.drop(['native-country', 'Unnamed: 0', 'hours-per-week', 'fnlwgt', 'race', 'education-num', 'education'], inplace=True, axis=1)\n",
    "display(dataDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef717ce6",
   "metadata": {},
   "source": [
    "[2] 데이터 확인 및 전처리 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c955a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       46043 non-null  object\n",
      " 2   marital-status  48842 non-null  object\n",
      " 3   occupation      46033 non-null  object\n",
      " 4   relationship    48842 non-null  object\n",
      " 5   sex             48842 non-null  object\n",
      " 6   capital-gain    48842 non-null  int64 \n",
      " 7   capital-loss    48842 non-null  int64 \n",
      " 8   class           48842 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 3.4+ MB\n",
      "None \n",
      "\n",
      "                age  capital-gain  capital-loss\n",
      "count  48842.000000  48842.000000  48842.000000\n",
      "mean      38.643585   1079.067626     87.502314\n",
      "std       13.710510   7452.019058    403.004552\n",
      "min       17.000000      0.000000      0.000000\n",
      "25%       28.000000      0.000000      0.000000\n",
      "50%       37.000000      0.000000      0.000000\n",
      "75%       48.000000      0.000000      0.000000\n",
      "max       90.000000  99999.000000   4356.000000\n",
      "                   age  capital-gain  capital-loss\n",
      "age           1.000000      0.077229      0.056944\n",
      "capital-gain  0.077229      1.000000     -0.031441\n",
      "capital-loss  0.056944     -0.031441      1.000000\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# [2-1] 데이터 확인\n",
    "# ==================================================================\n",
    "print(dataDF.info(), '\\n')\n",
    "print(dataDF.describe())\n",
    "\n",
    "# 상관계수\n",
    "numeric_columns = dataDF.select_dtypes(include=[np.number]).columns\n",
    "print(dataDF[numeric_columns].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ebbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass         2799\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "class                0\n",
      "dtype: int64\n",
      "28694\n",
      "age: 216개\n",
      "capital-gain: 4035개\n",
      "capital-loss: 2282개\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# [2-2] 결측치, 중복값, 이상치 처리\n",
    "# ==================================================================\n",
    "# 결측치 확인\n",
    "print(dataDF.isnull().sum())        # 결측치 존재\n",
    "                                    # workclass : 고용형태 - 없는 건 기타로 넣기\n",
    "                                    # occupation : 직업종류 - 없는 건 기타로 넣기\n",
    "\n",
    "# 중복값 확인\n",
    "print(dataDF.duplicated().sum())    # 중복값 0\n",
    "\n",
    "# 이상치 확인(IQR 기반)\n",
    "for col in numeric_columns:\n",
    "    Q1 = dataDF[col].quantile(0.25)\n",
    "    Q3 = dataDF[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = dataDF[(dataDF[col] < lower) | (dataDF[col] > upper)]\n",
    "    print(f\"{col}: {len(outliers)}개\")\n",
    "\n",
    "    # capital-gain, capital-loss는 연소득을 강하게 나타내는 케이스라서, 제거하지 않기로 함\n",
    "    # adult, education_num은 그럴 수 있다고 생각함 -> 제거X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b9c12",
   "metadata": {},
   "source": [
    "[3] 피쳐와 타겟 분리 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688adf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetSR  : (48842,)\n",
      "featureDF : (48842, 8)\n"
     ]
    }
   ],
   "source": [
    "# 타겟\n",
    "dataDF[\"class\"] = dataDF[\"class\"].map({\">50K\": 1, \"<=50K\": 0})  # 이상 : 1, 이하 : 0\n",
    "targetSR = dataDF[\"class\"]\n",
    "print(f\"targetSR  : {targetSR.shape}\")\n",
    "\n",
    "# 피쳐\n",
    "featureDF = dataDF.iloc[:, :-1]\n",
    "print(f\"featureDF : {featureDF.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75981898",
   "metadata": {},
   "source": [
    "[4] 수치형, 범주형 인코딩/전처리 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c45d8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 컬럼\n",
    "numeric_columns = featureDF.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# 결측치를 'Others'\n",
    "categorical_features_others = [\"workclass\", \"occupation\"]\n",
    "\n",
    "# 나머지 범주형\n",
    "categorical_features = ['marital-status', 'relationship']\n",
    "\n",
    "# 수치형 변환기\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# 범주형 변환기1 ('Others'로 채움)\n",
    "onehot_transformer_others = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Others\")),\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "# 범주형 변환기2 \n",
    "onehot_transformer_mode = Pipeline(steps=[\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "# 전체 전처리 결합\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_columns),\n",
    "        (\"ohe_others\", onehot_transformer_others, categorical_features_others),\n",
    "        (\"ohe_mode\", onehot_transformer_mode, categorical_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d9514",
   "metadata": {},
   "source": [
    "[4] 훈련용, 테스트용 데이터셋 분리 <hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470e1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (39073, 8)\n",
      "test  : (9769, 8)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    featureDF,\n",
    "    targetSR,\n",
    "    test_size=0.2,\n",
    "    stratify=targetSR\n",
    ")\n",
    "print(f\"train : {x_train.shape}\")\n",
    "print(f\"test  : {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7fe08",
   "metadata": {},
   "source": [
    "[5] all_estimators <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c09a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "AdaBoostClassifier: 0.8446105026102979\n",
      "BaggingClassifier: 0.8446105026102979\n",
      "BernoulliNB: 0.7545296345582967\n",
      "CalibratedClassifierCV: 0.8370355205241069\n",
      "DecisionTreeClassifier: 0.8431773978912888\n",
      "DummyClassifier: 0.7606715119254785\n",
      "ExtraTreeClassifier: 0.8318149247620023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     17\u001b[39m     model = Pipeline(steps=[\n\u001b[32m     18\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m, preprocessor),\n\u001b[32m     19\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m, estimatorClass())\n\u001b[32m     20\u001b[39m     ])\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     y_pred = model.predict(x_test)\n\u001b[32m     25\u001b[39m     accuracy = accuracy_score(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\pipeline.py:621\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    616\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    617\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    618\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    619\u001b[39m             all_params=params,\n\u001b[32m    620\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:184\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m                 this_warning_filter_dict[special_key] = this_value.pattern\n\u001b[32m    182\u001b[39m         warnings.filterwarnings(**this_warning_filter_dict, append=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:196\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    188\u001b[39m     tree._fit(\n\u001b[32m    189\u001b[39m         X,\n\u001b[32m    190\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:475\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    465\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    466\u001b[39m         splitter,\n\u001b[32m    467\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    472\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    473\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    478\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# [5-1] 모든 분류 모델 가져오기\n",
    "# ==================================================================\n",
    "\n",
    "estimators = all_estimators(type_filter=\"classifier\")\n",
    "print(len(estimators))\n",
    "\n",
    "# ==================================================================\n",
    "# [5-2] 각 모델 테스트\n",
    "# ==================================================================\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, estimatorClass in estimators:\n",
    "    try:\n",
    "\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", estimatorClass())\n",
    "        ])\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'model': name,\n",
    "            'accuracy': accuracy,\n",
    "            'class': estimatorClass\n",
    "        })\n",
    "        print(f\"{name}: {accuracy}\")\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# ==================================================================\n",
    "# [5-3] 결과 \n",
    "# ==================================================================\n",
    "\n",
    "resultDF = pd.DataFrame(results).sort_values('accuracy', ascending=False)\n",
    "print(\"\\n=== 모델 성능 순위 ===\")\n",
    "display(resultDF[['model', 'accuracy']].head(10))\n",
    "\n",
    "# 상위 1 bestModel\n",
    "bestModelClass = resultDF.iloc[0]['class']\n",
    "print(\"\\n=== Best Model Class ===\")\n",
    "print(bestModelClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab1db5",
   "metadata": {},
   "source": [
    "[7] Pipeline 구축 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850fe191",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Private'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_25856\\3697274165.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m     (\u001b[33m\"preprocessor\"\u001b[39m, preprocessor),\n\u001b[32m      4\u001b[39m     (\u001b[33m'model'\u001b[39m , bestModelClass())\n\u001b[32m      5\u001b[39m ])\n\u001b[32m      6\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m bestModel = finalPipeline.fit(x_train, y_train)\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m bestModel.score(x_test, y_test)\n\u001b[32m     10\u001b[39m print(classification_report(y_test, bestModel.predict(x_test)))\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1332\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m                 )\n\u001b[32m   1335\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    609\u001b[39m                 \u001b[33m\"`sklearn.set_config(enable_metadata_routing=True)`.\"\u001b[39m\n\u001b[32m    610\u001b[39m             )\n\u001b[32m    611\u001b[39m \n\u001b[32m    612\u001b[39m         routed_params = self._check_method_params(method=\u001b[33m\"fit\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m         Xt = self._fit(X, y, routed_params, raw_params=params)\n\u001b[32m    614\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"Pipeline\"\u001b[39m, self._log_message(len(self.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    615\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._final_estimator != \u001b[33m\"passthrough\"\u001b[39m:\n\u001b[32m    616\u001b[39m                 last_step_params = self._get_metadata_for_step(\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    543\u001b[39m                 step_params=routed_params[name],\n\u001b[32m    544\u001b[39m                 all_params=raw_params,\n\u001b[32m    545\u001b[39m             )\n\u001b[32m    546\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[32m    548\u001b[39m                 cloned_transformer,\n\u001b[32m    549\u001b[39m                 X,\n\u001b[32m    550\u001b[39m                 y,\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\joblib\\memory.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.func(*args, **kwargs)\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1480\u001b[39m     \"\"\"\n\u001b[32m   1481\u001b[39m     params = params \u001b[38;5;28;01mor\u001b[39;00m {}\n\u001b[32m   1482\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1483\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m hasattr(transformer, \u001b[33m\"fit_transform\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m             res = transformer.fit_transform(X, y, **params.get(\u001b[33m\"fit_transform\"\u001b[39m, {}))\n\u001b[32m   1485\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1486\u001b[39m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n\u001b[32m   1487\u001b[39m                 X, **params.get(\u001b[33m\"transform\"\u001b[39m, {})\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    906\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m    907\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    908\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    909\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    920\u001b[39m             Fitted scaler.\n\u001b[32m    921\u001b[39m         \"\"\"\n\u001b[32m    922\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    923\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1332\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m                 )\n\u001b[32m   1335\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    957\u001b[39m             Fitted scaler.\n\u001b[32m    958\u001b[39m         \"\"\"\n\u001b[32m    959\u001b[39m         xp, _, X_device = get_namespace_and_device(X)\n\u001b[32m    960\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m         X = validate_data(\n\u001b[32m    962\u001b[39m             self,\n\u001b[32m    963\u001b[39m             X,\n\u001b[32m    964\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2898\u001b[39m             out = y\n\u001b[32m   2899\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2900\u001b[39m             out = X, y\n\u001b[32m   2901\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2903\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2905\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1019\u001b[39m                         )\n\u001b[32m   1020\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1021\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1022\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1024\u001b[39m                 raise ValueError(\n\u001b[32m   1025\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1026\u001b[39m                 ) from complex_warning\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    874\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    875\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    876\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    877\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    879\u001b[39m \n\u001b[32m    880\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\khw27\\anaconda3\\envs\\ML311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Private'"
     ]
    }
   ],
   "source": [
    "finalPipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    ('model' , bestModelClass())\n",
    "])\n",
    "\n",
    "bestModel = finalPipeline.fit(x_train, y_train)\n",
    "\n",
    "bestModel.score(x_test, y_test)\n",
    "print(classification_report(y_test, bestModel.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
