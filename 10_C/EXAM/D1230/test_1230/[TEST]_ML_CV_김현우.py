## ======================================================================== ##
##                              머신러닝 문제                                 ##
## ======================================================================== ##


## -------------------------------------------------------------------------
## 문제 01. 아래 설명에 대한 적합한 학습 방식은?
## -------------------------------------------------------------------------
## → 정답(label)이 있는 데이터를 사용하여 학습           : 지도학습
## → 정답 없이 데이터의 구조나 특징, 패턴을 찾는 학습 방식 : 비지도학습


## -------------------------------------------------------------------------
## 문제 02. 다중 분류 문제에서 모든 클래스 쌍에 대해 이진 분류기를 학습하는 전략으로
##         클래스 수가 많아질수록 학습해야 할 분류기 개수가 급격히 증가하는 전략은?
## -------------------------------------------------------------------------
## → OVR


## -------------------------------------------------------------------------
## 문제 03. 지도학습과 비지도학습의 학습 목적 차이를 한 문장으로 설명하시오.
## -------------------------------------------------------------------------
## → 지도학습은 정답을 통해 특정 값/클래스를 예측, 비지도학습은 데이터의 패턴과 구조를 찾기 위해서 사용함



## -------------------------------------------------------------------------
## 문제 04. KNN 학습 알고리즘에 대해 답하세요.
## -------------------------------------------------------------------------
## → KNN에서 예측 시 가장 핵심적으로 사용하는 개념 : 거리
## → KNN에서 k 값이 너무 작을 경우 발생하는 문제  : 과적합



## -------------------------------------------------------------------------
## 문제 05. 의사결정나무에서 엔트로피 감소량을 의미하는 지표는?
## -------------------------------------------------------------------------
## → 정보 이득


## -------------------------------------------------------------------------
## 문제 06. 의사결정나무가 과대적합되기 쉬운 이유를 한 문장으로 서술하세요.
## -------------------------------------------------------------------------
## → 분할 기준이 명확하게 설정해두지 않으면 깊이를 제한하지 않고 계속해서 성장할 수 있기 때문이다.



## -------------------------------------------------------------------------
## 문제 07. Random Forest 학습 알고리즘에 대해 답하세요.
## -------------------------------------------------------------------------
## → 결합 모델 종류  : 배깅
## → 트리별 데이터셋 : 부트스트랩 샘플(중복 허용)



## -------------------------------------------------------------------------
## 문제 08. 모델에 대한 설명으로 빈칸 채우세요.
## -------------------------------------------------------------------------
## → Bagging은 데이터의 __________을(를) 다르게 하여 모델을 학습 : 샘플
## → Boosting은 이전 모델의 __________에 더 집중하여 학습 : 오류/오차



## -------------------------------------------------------------------------
## 문제 09. 모델 성능에 대한 설명으로 답하세요.
## -------------------------------------------------------------------------
## → 훈련 성능은 높고 테스트 성능이 낮은 현상           :  과적합
## → 모델 복잡도가 너무 낮아 성능이 전반적으로 낮은 상태  : 과소적합
## → 훈련과 테스트 성능이 모두 균형 잡힌 상태           : 최적적합



## -------------------------------------------------------------------------
## 문제 10. 기계학습 중 하나로 아래 설명에 대해 답하세요.
## -------------------------------------------------------------------------
## → 여러 모델의 예측을 결합하여 성능을 향상시키는 기법 : 앙상블
## → 해당 기법의 대표적인 종류 3가지 : 배깅, 부스팅, 



## -------------------------------------------------------------------------
## 문제 11. 모델 학습에 사용하는 데이터셋에 대한 설명입니다. 답하세요.
## -------------------------------------------------------------------------
## → 모델 학습에 직접 사용되는 데이터셋         : 훈련(train) 데이터셋
## → 하이퍼파라미터 튜닝에 사용되는 데이터셋     : 검증(valid) 데이터셋
## → 최종 성능 평가에만 사용되는 데이터셋       : 테스트(test) 데이터셋



## -------------------------------------------------------------------------
## 문제 12. 학습 과정에서 데이터로부터 자동으로 학습되는 값은?
## -------------------------------------------------------------------------
## → 파라미터



## -------------------------------------------------------------------------
## 문제 13. KNN이 고차원 데이터에서 성능이 저하되는 현상 무엇이라 하는가?
## -------------------------------------------------------------------------
## → 차원의 저주



## -------------------------------------------------------------------------
## 문제 14. 의사결정나무에서 분할 기준 관련 문제입니다. 
## -------------------------------------------------------------------------
## → 분할 기준 지표 : 엔트로피, 지니 계수
## → 공통     목적 : 불순도를 제거해줌



## -------------------------------------------------------------------------
## 문제 15. 학습 전에 사람이 설정해야 하는 값은?
## -------------------------------------------------------------------------
## → 하이퍼파라미터


## -------------------------------------------------------------------------
## 문제 16. 데이터를 동일 크기 여러 개로 나누어 반복 학습·검증하는 기법은?
## -------------------------------------------------------------------------
## → 교차 검증 기법


## -------------------------------------------------------------------------
## 문제 17. 회귀의 성능 지표입니다. 설명해 해당하는 성능 지표는?
## -------------------------------------------------------------------------
## → 실제값과 예측값 차이의 제곱 평균 지표 : MSE
## → 결정계수라고 불리는 회귀 성능 지표    : R^2



## -------------------------------------------------------------------------
## 문제 18. 모델 성능 향상을 위한 하이퍼파라미터 탐색 방법 설명입니다. 해당 방법은?
## -------------------------------------------------------------------------
## → 모든 하이퍼파라미터 조합을 탐색하는 방법 : GridSearch
## → 무작위로 일부 조합만 탐색하는 방법      : RandomSearch



## -------------------------------------------------------------------------
## 문제 19. 특성 공학의 주요 목적 한 가지는?
## -------------------------------------------------------------------------
## → 모델 성능을 향상시키는 것


## -------------------------------------------------------------------------
## 문제 20. 모델이 지나치게 단순해 생기는 오류 성향은?
## -------------------------------------------------------------------------
## → 편향


## -------------------------------------------------------------------------
## 문제 21. 데이터에 지나치게 민감하여 성능 변동이 큰 성향은?
## -------------------------------------------------------------------------
## → 분산



## -------------------------------------------------------------------------
## 문제 22. K-Fold 교차검증에서 K가 의미하는 것은?
## -------------------------------------------------------------------------
## → 데이터를 분할하는 폴드의 개수



## -------------------------------------------------------------------------
## 문제 23. 학습 과정에서 테스트 정보가 모델에 유입되는 문제는?
## -------------------------------------------------------------------------
## → 데이터 누수



## -------------------------------------------------------------------------
## 문제 24. 분류의 성능 지표입니다. 설명해 해당하는 성능 지표는?
## -------------------------------------------------------------------------
## → 전체 예측 중 맞게 예측한 비율      : accuracy
## →  Precision과 Recall의 조화 평균  : F1 Score



## -------------------------------------------------------------------------
## 문제 25. 데이터 분할 전에 스케일링을 수행하면 데이터 누수가 발생하는 이유는?
## -------------------------------------------------------------------------
## → 데이터를 분할 하기 전에 스케일링을 하면 전체 데이터를 기준으로 하기 때문에 train 데이터가 섞일 수 있음



## -------------------------------------------------------------------------
## 문제 26. scikit-learn에서 기계학습관련 메서드는?
## -------------------------------------------------------------------------
## → 학습 수행              : fit()
## → 학습된 모델로 예측 수행  : predict()
## → 테스트 수행            : score()



## -------------------------------------------------------------------------
## 문제 27. 모델 학습의 일반적인 순서는?
## -------------------------------------------------------------------------
## → 데이터 수집 -> 데이터 전처리 -> 모델 선택 -> 모델 학습 -> 모델 평가 -> 성능 평가 -> 하이퍼파라미터 튜닝



## -------------------------------------------------------------------------
## 문제 28. Bias와 Variance 사이의 상충 관계를 무엇이라 하는가?
## -------------------------------------------------------------------------
## → Bias-Variance tradeoff



## -------------------------------------------------------------------------
## 문제 29. 특성 공학(Feature Engineering)이란 무엇인가?
## -------------------------------------------------------------------------
## → 특성공학이란 데이터의 기존 특성에서 유용한 특성들만 추출해서 더 높은 성능을 내기 위한 과정



## -------------------------------------------------------------------------
## 문제 30. 입력 특성과 출력 사이의 선형 관계를 가정하는 회귀 모델은?
## -------------------------------------------------------------------------
## → 선형회귀



## -------------------------------------------------------------------------
## 문제 31. 선형회귀 모델에서 학습되는 파라미터 두 가지는?
## -------------------------------------------------------------------------
## → 기울기, 절편



## -------------------------------------------------------------------------
## 문제 33. 입력 특성을 제곱, 세제곱 등으로 확장하여 비선형 관계를 표현하는 회귀는?
## -------------------------------------------------------------------------
## → Polynomial Regression



## -------------------------------------------------------------------------
## 문제 34. 다항회귀가 선형회귀의 일종으로 분류되는 이유는?
## -------------------------------------------------------------------------
## → 특성 자체는 비선형인데 파라미터값들이 선형을 띄기 때문이다.



## -------------------------------------------------------------------------
## 문제 35. 수치형 특성의 스케일 차이를 줄이기 위해 사용하는 전처리 기법은?
## -------------------------------------------------------------------------
## → 특성 스케일링



## -------------------------------------------------------------------------
## 문제 36. 수치형 특성의 스케일링 방법은?
## -------------------------------------------------------------------------
## → 평균 0, 분산 1로 변환          : 표준화
## → 모든 값을 0과 1 사이로 변환     : 정규화


## -------------------------------------------------------------------------
## 문제 37. 범주형 데이터를 숫자로 변환해야 하는 이유는?
## -------------------------------------------------------------------------
## → 머신러닝에서는 수치형 데이터셋을 선호하기 때문이다.


## -------------------------------------------------------------------------
## 문제 38. 범주형 특성을 정수 값으로 매핑하는 가장 단순한 인코딩 방식은?
## -------------------------------------------------------------------------
## → Label Encoding


## -------------------------------------------------------------------------
## 문제 39. 라벨 인코딩을 순서가 없는 범주형 데이터에 사용할 경우의 문제점은?
## -------------------------------------------------------------------------
## → 순서가 없는 범주형 데이터는 범주끼리의 대소 관계가 없는데, 인코딩 된 숫자에는 대소가 생겨서 데이터가 불안정해진다.



## -------------------------------------------------------------------------
## 문제 40. 기존 특성으로부터 새로운 특성을 생성하거나 변환하는 과정을 무엇이라 하는가?
## -------------------------------------------------------------------------
## → 특성 공학


## -------------------------------------------------------------------------
## 문제 41. 각 범주를 독립적인 이진 벡터로 표현하는 인코딩 방식은?
## -------------------------------------------------------------------------
## → Onehot Encoding



## -------------------------------------------------------------------------
## 문제 42. 전처리와 모델을 하나의 학습 흐름으로 묶어 데이터 누수를 방지하는 도구는?
## -------------------------------------------------------------------------
## → Pipeline


## -------------------------------------------------------------------------
## 문제 43. 고차원 문제를 완화하기 위해 범주형 인코딩 시 사용할 수 있는 방법 한 가지는?
## -------------------------------------------------------------------------
## → Target Encoding


## -------------------------------------------------------------------------
## 문제 44. 다항회귀에서 차수(degree)가 너무 커질 경우 발생하기 쉬운 문제는?
## -------------------------------------------------------------------------
## → 과적합



## -------------------------------------------------------------------------
## 문제 45. 원-핫 인코딩의 대표적인 단점 한 가지 및 해당 현상을 무엇이라 하는가?
## -------------------------------------------------------------------------
## → 단점 : 차원이 너무 많아져서 차원의 저주에 걸릴 수 있다
## → 현상 : 차원의 저주



## -------------------------------------------------------------------------
## 문제 46. 타깃 인코딩(Target Encoding)의 핵심 아이디어는?
## -------------------------------------------------------------------------
## → 각각의 범주들을 Target, 즉 목표값의 평균으로 인코딩하는 것이다.


## -------------------------------------------------------------------------
## 문제 47. 결측치(missing value)를 처리하는 전처리 방법 한 가지는?
## -------------------------------------------------------------------------
## → 결측치를 제거하거나 평균, 중앙값으로 대체



## -------------------------------------------------------------------------
## 문제 48. 결측치를 제거(drop)하는 방식이 항상 좋은 선택이 아닌 이유는?
## -------------------------------------------------------------------------
## → 결측치를 모두 제거할 시에는 자칫 잘못하면 정말 유용한 정보가 제거될 수 있기 때문이다.


## -------------------------------------------------------------------------
## 문제 49. 불균형 분류에서 데이터 분할 시 클래스 비율을 유지하도록 설정하려 한다.
##         빈칸에 들어갈 매개변수를 채우시오.
## -------------------------------------------------------------------------
## X_train, X_test, y_train, y_test = train_test_split(
##     X, y,
##     test_size=0.25,
##     random_state=42,
##     __________=y    # (1) 클래스 비율 유지
## )
## -------------------------------------------------------------------------
## → stratify



## -------------------------------------------------------------------------
## 문제 50. 특성공학의 주요 목적 한 가지는?
## -------------------------------------------------------------------------
## → 모델의 성능을 높이기 위함.


## -------------------------------------------------------------------------
## 문제 51. 특성 스케일링이 필요한 이유 한 가지는?
## -------------------------------------------------------------------------
## → 특정한 피쳐가 너무 과도한 영향력을 발휘하지 못하게 하기 위해서이다.


## -------------------------------------------------------------------------
## 문제 52. 선형회귀에서 과대적합을 완화하기 위해 가중치 크기에 패널티를 주는 기법은?
## -------------------------------------------------------------------------
## → Ridge, Rasso


## -------------------------------------------------------------------------
## 문제 53. 선형 회귀 모델의 패널티 부여 기법으로 아래 칸 채우세요.
## -------------------------------------------------------------------------
## →            회귀 모델           |       패널티        |    가중치 값  
## → ---------------------------------------------------------------------- 
## →  릿지 회귀(Ridge Regression)   |      (1)           |       (2)
## →  라쏘 회귀(Lasso Regression)   |      (3)           |       (4)
## → ---------------------------------------------------------------------- 
## → (1) L2
## → (2) 0에 수렴
## → (3) L1
## → (4) 0


## -------------------------------------------------------------------------
## 문제 54. 릿지와 라쏘의 장점을 모두 결합한 회귀 모델은?
## -------------------------------------------------------------------------
## → Elastic Net



## -------------------------------------------------------------------------
## 문제 55. 아래 경우에 적합한 회귀 모델은?
## -------------------------------------------------------------------------
## → 특성 수가 많고 상관관계가 높은 경우에 적합한 회귀 모델 : Ridge
## → 특성 선택이 중요한 경우 선호되는 회귀 모델 : Rasso



## -------------------------------------------------------------------------
## 문제 56. 모델 학습 과정에서 검증 데이터가 필요한 이유를 한 문장으로 설명하시오.
## -------------------------------------------------------------------------
## → 모델의 일반화 성능을 평가하기 위해서이다.


## -------------------------------------------------------------------------
## 문제 57. 빈칸에 들어갈 코드(클래스/메서드)를 채우시오.
## -------------------------------------------------------------------------
## pipe = Pipeline([
##     ("scaler", ____________),                 # (1)
##     ("svc", SVC(kernel="rbf", C=1.0, probability=True, random_state=42))
## ])
##
## pipe.__________(X_train, y_train)            # (2)
## pred = pipe.__________(X_test)               # (3)
## -------------------------------------------------------------------------

## → (1) Standard Scaler()
## → (2) fit
## → (3) predict



## -------------------------------------------------------------------------
## 문제 58. 데이터 불균형(Class Imbalance)이란 무엇인가?
## -------------------------------------------------------------------------
## → 각각의 클래스 샘플 수가 지나치게 차이가 나는 상태이다.



## -------------------------------------------------------------------------
## 문제 59. 데이터 불균형 문제가 주로 발생하는 분야 한 가지는?
## -------------------------------------------------------------------------
## → 금융 사기


## -------------------------------------------------------------------------
## 문제 60. Precision, Recall, F1-score에서 사용하는 평균 방식의 종류 3가지는?
## -------------------------------------------------------------------------
## → micro, macro,가중치


## -------------------------------------------------------------------------
## 문제 61. 아래 설명에 대한 지표는?
## -------------------------------------------------------------------------
## → 실제 양성 중에서 모델이 맞게 예측한 비율을 의미하는 지표 : 재현율
## → 모델이 양성이라고 예측한 것 중 실제로 맞은 비율을 의미하는 지표 : 정밀도



## -------------------------------------------------------------------------
## 문제 62. 소수 클래스 데이터를 복제하여 수를 늘리는 방법은?
## -------------------------------------------------------------------------
## → 소수 클래스 데이터를 복제하여 수를 늘리는 방법     :  오버샘플링
## → 다수 클래스 데이터를 일부 제거하여 균형 맞추는 방법 : 언더샘플링



## -------------------------------------------------------------------------
## 문제 63. 단순 오버샘플링의 주요 단점 한 가지는?
## -------------------------------------------------------------------------
## → 단순 오버샘플링의 주요 단점 한 가지 : 과적합
## → 단순 언더샘플링의 주요 단점 한 가지 : 정보 손실 



## -------------------------------------------------------------------------
## 문제 64. 다중 분류 문제에서 하나의 클래스를 나머지 모든 클래스와 구분하여
##         여러 개의 이진 분류기를 학습하는 전략은?
## -------------------------------------------------------------------------
## → OVR



## -------------------------------------------------------------------------
## 문제 65. 다중 분류 문제에서 하나의 클래스를 나머지 모든 클래스와 구분하여
##         여러 개의 이진 분류기를 학습하는 전략은?
## -------------------------------------------------------------------------
## → 각 클래스를 동일한 중요도로 평가 : macro
## → 전체 데이터를 하나로 보고 계산   : micro
## → 클래스별 데이터 수 비율을 반영  : 가중치


## ====================================================================== ##
##                          OpenCV Python문제                              ##
## ====================================================================== ##
## -------------------------------------------------------------------------
## 문제 01. OpenCV에서 마스크(mask)란 무엇인가?
## -------------------------------------------------------------------------
## → 특정 영역만 추출해서 처리하기 위해 사용하는 것



## -------------------------------------------------------------------------
## 문제 02. 디지털 영상에서 픽셀(pixel)이 의미하는 것은?
## -------------------------------------------------------------------------
## → 영상을 구성하는 최소 단위



## -------------------------------------------------------------------------
## 문제 03. 컬러 스페이스 변환을 수행하는 근본적인 목적은?
## -------------------------------------------------------------------------
## → 특정한 색상들을 더 효과적으로 표현하기 위해서이다.


## -------------------------------------------------------------------------
## 문제 04. 그레이스케일 영상에서 픽셀 값이 클수록 의미하는 것은?
## -------------------------------------------------------------------------
## → 픽셀 값이 높을수록 밝기가 올라감


## -------------------------------------------------------------------------
## 문제 05. 컬러 영상에서 채널(channel)이란 무엇인가?
## -------------------------------------------------------------------------
## → 채널은 R, G, B 같은 개별 성분들을 의미한다.


## -------------------------------------------------------------------------
## 문제 06. 해상도(resolution)란 무엇을 의미하는가?
## -------------------------------------------------------------------------
## → 가로, 세로의 픽셀 개수이다.


## -------------------------------------------------------------------------
## 문제 07. 비트 심도(bit depth)란 무엇인가?
## -------------------------------------------------------------------------
## → 색상을 표현하는 단계이다.


## -------------------------------------------------------------------------
## 문제 08. 8비트 그레이스케일 영상에서 표현 가능한 픽셀 값 범위는?
## -------------------------------------------------------------------------
## → 0~255


## -------------------------------------------------------------------------
## 문제 09. 비트 심도가 커질수록 영상에서 좋아지는 점 한 가지는?
## -------------------------------------------------------------------------
## → 영상의 해상도가 올라가고 색상이 더 뚜렷해진다.


## -------------------------------------------------------------------------
## 문제 10. ROI(Region of Interest)란 무엇인가?
## -------------------------------------------------------------------------
## → ROI는 사용자가 관심 있어하는 영역만 따로 추출하는 작업을 의미한다.



## -------------------------------------------------------------------------
## 문제 11. 영상 처리에서 ROI를 사용하는 가장 큰 목적은?
## -------------------------------------------------------------------------
## → 영상을 처리하는데 있어서 더 높은 성능을 내기 위해 불필요한 부분을 제거하고 꼭 필요한 관심영역만 추출하기 위해서이다.


## -------------------------------------------------------------------------
## 문제 12. ROI를 잘못 설정했을 때 발생할 수 있는 문제 한 가지는?
## -------------------------------------------------------------------------
## → ROI(관심영역)을 잘못 설정햇을 때는 중요한 영역을 놓칠 수 있다.


## -------------------------------------------------------------------------
## 문제 13. 색공간(Color Space)이란 무엇인가?
## -------------------------------------------------------------------------
## → 색공간은 HSV, GRAYSCALE 같이 색상을 표현할 수 있는 여러 방법들이다.



## -------------------------------------------------------------------------
## 문제 14. RGB 색공간의 대표적인 단점 한 가지는?
## -------------------------------------------------------------------------
## → RGB의 단점은 조명 변화에 취약할 수 있다는 점이다.


## -------------------------------------------------------------------------
## 문제 15. HSV 색공간에서 H, S, V가 각각 의미하는 것은?
## -------------------------------------------------------------------------
## →  H:색상, S:채도, V:명도


## -------------------------------------------------------------------------
## 문제 16. 색상 기반 객체 검출에서 HSV 색공간이 자주 사용되는 이유는?
## -------------------------------------------------------------------------
## → HSV 색공간은 밝기에 강하기 때문에 색상을 더 잘 검출할 수 있다.

## -------------------------------------------------------------------------
## 문제 17. YCbCr 색공간에서 Y 성분이 의미하는 것은?
## -------------------------------------------------------------------------
## → 밝기



## -------------------------------------------------------------------------
## 문제 18. 블러링(Filtering)의 대표적인 목적 한 가지는?
## -------------------------------------------------------------------------
## → 노이즈 제거 



## -------------------------------------------------------------------------
## 문제 19. 히스토그램(histogram)이 영상 처리에서 나타내는 정보는?
## -------------------------------------------------------------------------
## → 픽셀 값들의 분포



## -------------------------------------------------------------------------
## 문제 20. 이진화(binarization)란 무엇인가?
## -------------------------------------------------------------------------
## → 영상을 흑백 두가지로만 나타내는 것(0과 255)