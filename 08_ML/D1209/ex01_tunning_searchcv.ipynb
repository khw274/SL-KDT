{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a26ff6",
   "metadata": {},
   "source": [
    "##### [모델 성능 개선 - 튜닝]\n",
    "- scikit-learn에서는 튜닝을 위한 클래스 제공\n",
    "    * GridSearchCV\n",
    "    * RandomedSearchCV\n",
    "    * CV 즉, 교차검증 함께 진행\n",
    "    * 시간이 오래 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a700d8f",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <HR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9ef94de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# [1-1] 모듈 로딩\n",
    "# --------------------------------------------------\n",
    "# 데이터 전처리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessing\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# 머신러닝 \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV    # 튜닝 관련\n",
    "from sklearn.neighbors import KNeighborsClassifier                      # 학습 알고리즘\n",
    "from sklearn.model_selection import train_test_split                    # 데이터셋 관련\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "62baaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# [1-2] 데이터 준비\n",
    "# --------------------------------------------------\n",
    "FILE_NAME = '../Data/iris.csv'\n",
    "irisDF = pd.read_csv(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d1c0f547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# [1-3] 데이터 확인\n",
    "# --------------------------------------------------\n",
    "# display(irisDF.head(3))\n",
    "# display(irisDF.info())\n",
    "preprocessing.check_data(irisDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96688d7",
   "metadata": {},
   "source": [
    "[2] 데이터 전처리 <HR>\n",
    "- 기본 데이터 전처리 : 결측치, 중복값, 피쳐별 분포, 이상치\n",
    "- 학습관련 전처리 : 학습 알고리즘에 따른 처리, 피쳐와 타겟, 피쳐와 피쳐\n",
    "- 학습관련 분리 : 피쳐와 타겟 분리, 학습용/검증용/테스트용 분리\n",
    "- 학습데이터 전처리 : 이상치, 스케일러, 인코딩...\n",
    "- 검증/테스트용 데이터 : 학습 알고리즘에 대입하기 위한 형태 맞춤 진행 \n",
    "    - ★ 이상치 그대로/변경 여부 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e2bd5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# [2-1] 피쳐와 타겟 분리\n",
    "# --------------------------------------------------\n",
    "featureDF = irisDF.drop('variety', axis=1)\n",
    "targetSR = irisDF['variety']\n",
    "\n",
    "# Train / Test 분리(검증은 CV로 처리)\n",
    "train_feature, test_feature, train_target, test_target = train_test_split(\n",
    "    featureDF,\n",
    "    targetSR,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=targetSR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "10f84d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# [2-2] 학습 알고리즘을 위한 전처리 : 거리기반 알고리즘 스케일러\n",
    "# --------------------------------------------------\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "# Train에 대해서만 fit\n",
    "train_feature_scaled = std_scaler.fit_transform(train_feature)\n",
    "\n",
    "# Test는 transform만 , fit은 이미 완료\n",
    "test_feature_scaled = std_scaler.transform(test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4ede9",
   "metadata": {},
   "source": [
    "[3] 학습 및 검증, 하이퍼파라미터 찾기 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d24a8",
   "metadata": {},
   "source": [
    "**- GridSearchCV: 모든 파라미터 조합으로 모델 생성 및 학습/검증 진행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b50e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "▶ GridSearchCV 최적 하이퍼파라미터:  {'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "▶ GridSearchCV CV 최고 정확도    :  0.9666666666666668\n",
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_neighbors', 'param_p', 'param_weights', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])\n",
      "\n",
      "▶ Test Accuracy (GridSearch 최적 모델):  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 1) 기본 모델\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 2) 그리드 탐색용 하이퍼파라미터 설정\n",
    "#    키 -> 학습 알고리즘의 매개변수 즉, 속성명\n",
    "#    값 -> 학습 알고리즘의 매개변수 즉, 속성에 적용할 수 있는 값들\n",
    "param_grid = {'n_neighbors':[1, 3, 5, 7, 9, 11, 13, 15],\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'p':[1, 2]}    # 1: 맨해튼 거리, 2: 유클리드 거리\n",
    "\n",
    "# 3) GridSearchCV 설정\n",
    "grid_search = GridSearchCV(estimator=knn,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n",
    "\n",
    "# 4) 학습 (★ 반드시 Train 데이터만 사용)\n",
    "grid_search.fit(train_feature_scaled, train_target)\n",
    "\n",
    "# => 학습 즉, fit() 이후 모델 파라미터(파라미터이름_)들\n",
    "print(\"▶ GridSearchCV 최적 하이퍼파라미터: \", grid_search.best_params_)\n",
    "print(\"▶ GridSearchCV CV 최고 정확도    : \", grid_search.best_score_)\n",
    "\n",
    "print(grid_search.cv_results_.keys())\n",
    "# resultDF = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# display(\"▶ 교차검증 결과    : \", resultDF)\n",
    "\n",
    "# 5) 최적 모델로 Test 성능 평가\n",
    "best_knn_grid = grid_search.best_estimator_\n",
    "y_pred_grid = best_knn_grid.predict(test_feature_scaled)\n",
    "\n",
    "print(\"\\n▶ Test Accuracy (GridSearch 최적 모델): \", best_knn_grid.score(test_feature_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ba8b1",
   "metadata": {},
   "source": [
    "**- RandomizedSearchCV : GridSearchCV의 단점인 시간 개선 튜닝 방법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3439bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "▶ RandomizedSearchCV 최적 하이퍼파라미터:  {'n_neighbors': 24, 'p': 1, 'weights': 'distance'}\n",
      "▶ RandomizedSearchCV CV 최고 정확도    :  0.975\n",
      "\n",
      "▶ Test Accuracy (RandomSearch 최적 모델):  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 모듈\n",
    "from scipy.stats import randint\n",
    "\n",
    "# 1) 기본 모델\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 2) 랟덤 탐색용 분포 설정\n",
    "param_dist = {'n_neighbors':randint(1, 31), # 1 ~ 30 사이의 정수\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'p':[1, 2]}    # 1: 맨해튼 거리, 2: 유클리드 거리\n",
    "\n",
    "# 3) GridSearchCV 설정\n",
    "random_search = RandomizedSearchCV(estimator=knn,\n",
    "                                  param_distributions=param_dist,\n",
    "                                  \n",
    "                                  n_iter=20,   # 20개 조합만 랜덤으로 시도\n",
    "                                  cv=5,\n",
    "                                  scoring='accuracy',\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=42,\n",
    "                                  verbose=2)\n",
    "\n",
    "# 4) 학습 (★ 반드시 Train 데이터만 사용)\n",
    "random_search.fit(train_feature_scaled, train_target)\n",
    "\n",
    "print(\"▶ RandomizedSearchCV 최적 하이퍼파라미터: \", random_search.best_params_)\n",
    "print(\"▶ RandomizedSearchCV CV 최고 정확도    : \", random_search.best_score_)\n",
    "\n",
    "# 5) 최적 모델로 Test 성능 평가\n",
    "best_knn_rand = random_search.best_estimator_\n",
    "\n",
    "print(\"\\n▶ Test Accuracy (RandomSearch 최적 모델): \", best_knn_rand.score(test_feature_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103d0b2",
   "metadata": {},
   "source": [
    "#### [데이터 전처리 - 1 : 인코딩 & 디코딩]\n",
    "- 범주형 => 수치형 : 인코딩(Encoding)\n",
    "- 수치형 => 범주형 : 디코딩(Decoding)\n",
    "- scikit-learn의 preprocessing 서브 패키지에 제공\n",
    "    * LabelEncoder   : 타겟/라벨/클래스 컬럼 전용 => 0 ~ 클래스개수-1\n",
    "    * OrdinalEncoder : 범주형 피쳐에 대한 인코딩 => 정수값 변환, 순서가 중요한 피쳐\n",
    "        - 예: 만족도, 석차, 등급, ...\n",
    "    * OneHotEncoder  : 범주형 피쳐에 대한 인코딩 => 값의 의미가 없고 데이터 의미가 중요한 피쳐\n",
    "        - 예: 성별, 혈액형, 도시명, ...\n",
    "    * TargetEncoder  : OneHotEncoder에 대한 대안. 타겟/라벨/클래스 컬럼의 데이터 타입에 따른 인코딩 진행\n",
    "        - 예: 이진, 다중, 수치형, 연속형 ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56798c41",
   "metadata": {},
   "source": [
    "[1] LabelEncoder <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "38efaf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_ : ['amsterdam' 'paris' 'tokyo'], {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['paris', 'paris', 'tokyo'], dtype='<U9')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 관련 모듈 로딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 인스턴스 생성\n",
    "lencoder = LabelEncoder()\n",
    "\n",
    "# 학습 진행 : 인코딩 대상 적용\n",
    "lencoder.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "\n",
    "# 모델 파라미터 확인\n",
    "print(f\"classes_ : {lencoder.classes_}, {lencoder.get_params()}\")\n",
    "\n",
    "# 변형 - 반환값(ndarray)\n",
    "data = [\"paris\", \"paris\", \"tokyo\"]\n",
    "lencoder.transform(data)\n",
    "encoding = lencoder.transform(data)\n",
    "\n",
    "# 복원/디코딩 => ndarray\n",
    "lencoder.inverse_transform(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646ade7",
   "metadata": {},
   "source": [
    "[2] OrdinalEncoder <hr>\n",
    "- 순서가 중요\n",
    "- 성별일 경우 순서가 중요하지 않으므로 onHot 인코더 사용 권장\n",
    "- 평점 같은 경우 순서가 중요함으로 Ordinal 인코더 사용 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9e7ff050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names_in_ : ['gender']\n",
      "categories        : auto\n",
      "n_features_in_    : 1\n",
      "인코딩 결과 :  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]]\n",
      "복원/디코딩 결과 :  [['F']\n",
      " ['F']\n",
      " ['M']\n",
      " ['F']\n",
      " ['M']\n",
      " ['UN']]\n"
     ]
    }
   ],
   "source": [
    "# 관련 모듈 로딩\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# 테스트용 데이터\n",
    "data = pd.DataFrame({'gender':['F', 'F', 'M', 'F', 'M', 'UN']})\n",
    "\n",
    "# 인스턴스 생성\n",
    "ordEncoder = OrdinalEncoder()\n",
    "\n",
    "# 데이터에 대한 인코딩 설정\n",
    "ordEncoder.fit(data)\n",
    "\n",
    "# 설정된 인코딩 정보 확인\n",
    "print(f\"feature_names_in_ : {ordEncoder.feature_names_in_}\")\n",
    "print(f\"categories        : {ordEncoder.categories}\")\n",
    "print(f\"n_features_in_    : {ordEncoder.n_features_in_}\")\n",
    "\n",
    "# 인코딩 진행\n",
    "encoding = ordEncoder.transform(data)\n",
    "print(\"인코딩 결과 : \", encoding)\n",
    "\n",
    "# 복원/디코딩\n",
    "print(\"복원/디코딩 결과 : \", ordEncoder.inverse_transform(encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f4c7a",
   "metadata": {},
   "source": [
    "[3] OneHotEncoder <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b3cd0feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories        : auto\n",
      "feature_names_in_ : ['gender']\n",
      "인코딩 결과 :  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]]\n",
      "복원/디코딩 결과 :  [['F']\n",
      " ['F']\n",
      " ['M']\n",
      " ['F']\n",
      " ['M']\n",
      " ['UN']]\n"
     ]
    }
   ],
   "source": [
    "# 관련 모듈 로딩\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# 테스트용 데이터\n",
    "data = pd.DataFrame({'gender':['F', 'F', 'M', 'F', 'M', 'UN']})\n",
    "\n",
    "# 인스턴스 생성 : 압축출력 설정 sparse_output : [기본값=True]\n",
    "ohEncoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# 데이터에 대한 인코딩 설정\n",
    "ohEncoder.fit(data)\n",
    "\n",
    "# 설정된 인코딩 정보 확인\n",
    "print(f\"categories        : {ohEncoder.categories}\")\n",
    "print(f\"feature_names_in_ : {ohEncoder.feature_names_in_}\")\n",
    "\n",
    "# 인코딩 진행\n",
    "encoding = ordEncoder.transform(data)\n",
    "print(\"인코딩 결과 : \", encoding)\n",
    "\n",
    "# 복원/디코딩\n",
    "print(\"복원/디코딩 결과 : \", ordEncoder.inverse_transform(encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def26da",
   "metadata": {},
   "source": [
    "[4] TargetEncoder <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f3bf95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 모듈 로딩\n",
    "from sklearn.preprocessing import TargetEncoder, OneHotEncoder\n",
    "\n",
    "# 테스트 데이터\n",
    "df = pd.DataFrame({\n",
    "    \"city\": [\"Seoul\", \"Busan\", \"Seoul\", \"Daegu\", \"Busan\", \"Seoul\", \"Incheon\", \"Daegu\", \"Busan\", \"Seoul\"],\n",
    "    \"age\":  [25, 32, 41, 23, 37, 29, 33, 45, 28, 40],\n",
    "    \"y\":    [1, 0, 1, 0, 0, 1, 1, 0, 0, 1]  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2f4ed342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25]\n",
      " [32]\n",
      " [41]\n",
      " [23]\n",
      " [37]\n",
      " [29]\n",
      " [33]\n",
      " [45]\n",
      " [28]\n",
      " [40]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  1, 25],\n",
       "       [ 1,  0,  0,  0, 32],\n",
       "       [ 0,  0,  0,  1, 41],\n",
       "       [ 0,  1,  0,  0, 23],\n",
       "       [ 1,  0,  0,  0, 37],\n",
       "       [ 0,  0,  0,  1, 29],\n",
       "       [ 0,  0,  1,  0, 33],\n",
       "       [ 0,  1,  0,  0, 45],\n",
       "       [ 1,  0,  0,  0, 28],\n",
       "       [ 0,  0,  0,  1, 40]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피쳐 컬럼 : city, age / 타겟 컬럼 : y\n",
    "# 피쳐 컬럼 중 텍스트 데이터의 city ==> 수치화 즉, 인코딩\n",
    "\n",
    "# OneHOT\n",
    "# 인스턴스 생성 : 압축출력 설정 sparse_output : [기본값=True]\n",
    "ohEncoder = OneHotEncoder(sparse_output=False, dtype=int)\n",
    "cityArr = ohEncoder.fit_transform(df[['city']])\n",
    "cityArr.tolist()\n",
    "\n",
    "# df['city_onehot'] = cityArr.tolist()\n",
    "# print(df)\n",
    "cityArr = ohEncoder.fit_transform(df[['city']])\n",
    "ageArr = df[df.columns[1:-1]].values\n",
    "print(ageArr)\n",
    "\n",
    "np.concatenate((cityArr, ageArr), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
