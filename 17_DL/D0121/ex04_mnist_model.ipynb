{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a155af7",
   "metadata": {},
   "source": [
    "### 【 손글씨 숫자 인식 모델 구현 】\n",
    "- 데이터셋 : mnist_train.csv, mnist_test.csv\n",
    "- 학습종류 : 자동학습 - 다중클래스분류\n",
    "- 학습방법 : 인공신경망기반"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9847c6",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "884803b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1-1] 모듈 로딩\n",
    "import pandas as pd\n",
    "\n",
    "import torch                                        # 텐서 및 수치과학 함수들 관련 모듈\n",
    "import torch.nn as nn                               # 신경망 층 관련 모듈\n",
    "import torch.nn.functional as F                     # 신경망 함수들(AF, LF, MF) 모듈\n",
    "import torch.optim as optim                         # 신경망 최적화 모듈\n",
    "from torch.optim import Adam                        # Adam 최적화 알고리즘\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader    # pytorch의 데이터 로딩\n",
    "from torch.utils.data import Subset                 # pytorch의 데이터셋 관련 모듈\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b851d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1-2] 데이터 준비\n",
    "TRAIN_FILE = '../Data/mnist_train.csv'\n",
    "TEST_FILE  = '../Data/mnist_test.csv'\n",
    "\n",
    "# [1-3] 데이터 로딩\n",
    "trainDF = pd.read_csv(TRAIN_FILE, header=None)\n",
    "testDF  = pd.read_csv(TEST_FILE, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fc46f",
   "metadata": {},
   "source": [
    "[2] 커스텀 데이터셋 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "79624bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [2-1] 커스텀 데이터셋 클래스 정의\n",
    "# -------------------------------------------------------------------------------------\n",
    "# 클래스이름 : ClfDataset\n",
    "# 부모클래스 : Dataset\n",
    "# 오버라이딩 : _ _init_ _(self)         : [필수] 피쳐, 타겟, [선택]행수, 컬럼수, 타겟 수...\n",
    "#            _ _len_ _(self)          : len() 내장함수 실행 시 자동 호출, 샘플 수 반환\n",
    "#            _ _getitem_ _(self, idx) : 인스턴스명[idx] 시 자동 호출,\n",
    "#                                       idx에 해당하는 피쳐, 타겟을 텐서화 해서 반환\n",
    "# -------------------------------------------------------------------------------------\n",
    "class ClfDataset(Dataset):\n",
    "\n",
    "    #- 피쳐와 타겟 저장 및 기타 속성 초기화\n",
    "    def __init__(self, dataDF):\n",
    "        super().__init__()\n",
    "        ## 피쳐, 타겟 초기화 필수\n",
    "        self.x = dataDF[dataDF.columns[1:]].values\n",
    "        self.y = dataDF[dataDF.columns[0]].values\n",
    "\n",
    "\n",
    "    #- 데이터 샘플 수 반환 메서드 : len() 함수에 자동호출됨\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    #- 인덱스에 해당하는 피쳐와 타겟 텐서 반환 메서드 : 인스턴스명[index]에 자동호출됨\n",
    "    def __getitem__(self, index):\n",
    "        xTS = torch.tensor(self.x[index], dtype=torch.float32)\n",
    "        yTS = torch.tensor(self.y[index], dtype=torch.long)\n",
    "        return xTS, yTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4e2afdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allDS : 60000,  testDS : 10000\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [2-2] 커스텀 데이터셋 인스턴스 생성 및 사용\n",
    "# -------------------------------------------------------------------------------------\n",
    "allDS   = ClfDataset(trainDF)   ## <= trainDS, validDS 분리\n",
    "testDS  = ClfDataset(testDF)\n",
    "\n",
    "print(f'allDS : {len(allDS)},  testDS : {len(testDS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "998ef492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [2-3] 학습용/검증용/테스트용 데이터셋 분리\n",
    "# -------------------------------------------------------------------------------------\n",
    "# 학습용   : 순수 학습에 즉, 데이터셋에 규칙/패턴을 찾기 위한 데이터셋\n",
    "# 검증용   : 제대로 데이터셋에서 규칙/패턴을 찾는지 확인 용도\n",
    "#           에포크 단위로 찾은 규칙/패턴의 검증용으로 사용\n",
    "# 테스트용 : 데이터셋에 규칙/패턴 찾은 후 최종 테스트용으로 사용\n",
    "\n",
    "# 학습용 데이터셋에서 타겟/라벨만 추출\n",
    "targetList = allDS.y\n",
    "\n",
    "# 학습용 데이터셋에서 타겟/라벨만 추출\n",
    "dataNP = allDS.y.shape\n",
    "\n",
    "# 학습용 데이터셋에서 타겟/라벨 인덱스 생성\n",
    "dataIndexList = list(range(len(allDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8b4b555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용/검증용 데이터셋 인덱스 분리\n",
    "# - train_test_split() 함수 : train:test : 75:27 비율로 학습용, 테스트용 데이터셋 분리\n",
    "#                            stratify : 분류용 데이터셋의 경우 카테고리 비율 유지해서 데이터셋 분리\n",
    "X_trainIdx, X_validIdx, y_train, y_valid = train_test_split(dataIndexList,\n",
    "                                                            targetList,\n",
    "                                                            train_size=0.8,\n",
    "                                                            stratify=targetList,\n",
    "                                                            random_state=10)\n",
    "\n",
    "# print(f\"X_trainIdx : {len(X_trainIdx)}개, {type(X_trainIdx)}\")\n",
    "# print(f\"X_validIdx : {len(X_validIdx)}개, {type(X_validIdx)}\")\n",
    "# print(f\"testDS     : {len(testDS)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "130c97ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allDS   : 60000개, <class '__main__.ClfDataset'>\n",
      "trainDS : 48000개, <class 'torch.utils.data.dataset.Subset'>\n",
      "validDS : 12000개, <class 'torch.utils.data.dataset.Subset'>\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# 학습용/검증용 데이터셋 생성 ----> Dataset ---> 2개 Subset 분리\n",
    "# -------------------------------------------------------------------------------------\n",
    "trainDS = Subset(allDS, X_trainIdx)\n",
    "validDS = Subset(allDS, X_validIdx)\n",
    "\n",
    "print(f\"allDS   : {len(allDS)}개, {type(allDS)}\")\n",
    "print(f\"trainDS : {len(trainDS)}개, {type(trainDS)}\")\n",
    "print(f\"validDS : {len(validDS)}개, {type(validDS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90773a",
   "metadata": {},
   "source": [
    "[3] 모델 클래스 설계 <HR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "498a3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [3-1] 커스텀 모델 클래스 정의\n",
    "# -------------------------------------------------------------------------------------\n",
    "# 클래스이름 : MNISTModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 오버라이딩 : __init__(self)\n",
    "#            forward(self, x)\n",
    "# \n",
    "# 데이터셋:\n",
    "# - allDS: 60000개 (전체 MNIST 훈련 데이터)\n",
    "# - trainDS: 48000개 (80% 분할)\n",
    "# - validDS: 12000개 (20% 분할)\n",
    "# - 다중클래스 분류: 0~9 (10개 클래스)\n",
    "# -------------------------------------------------------------------------------------\n",
    "#               입력수           퍼셉트론수/출력수           AF(활성화함수)\n",
    "# -------------------------------------------------------------------------------------\n",
    "# 입력층           784                   784                \n",
    "# 은닉층1          784                   256                    ReLU\n",
    "# 은닉층2          256                   128                    ReLU\n",
    "# 은닉층3          128                    64                    ReLU\n",
    "# 출력층           64                     10                   Softmax  다중분류\n",
    "# -------------------------------------------------------------------------------------\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 입력: 784 (28x28 flatten)\n",
    "        # 은닉층1: 256 노드\n",
    "        # 은닉층2: 128 노드\n",
    "        # 은닉층3: 64 노드\n",
    "        # 출력: 10 (0~9 숫자 분류)\n",
    "        \n",
    "        self.hd1_layer = nn.Linear(784, 256)      # 첫 번째 완전연결층\n",
    "        self.hd2_layer = nn.Linear(256, 128)      # 두 번째 완전연결층\n",
    "        self.hd3_layer = nn.Linear(128, 64)       # 세 번째 완전연결층\n",
    "        self.out_layer = nn.Linear(64, 10)        # 출력층\n",
    "        \n",
    "        self.relu = nn.ReLU()               # 활성화 함수\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.relu(self.hd1_layer(x))\n",
    "        out = F.relu(self.hd2_layer(out))\n",
    "        out = F.relu(self.hd3_layer(out))\n",
    "        out = self.out_layer(out) # CrossEntropyLoss 안에 Softmax 내장\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "868f463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModel(\n",
      "  (hd1_layer): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (hd2_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (hd3_layer): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (out_layer): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MNISTModel                               [1, 10]                   --\n",
       "├─Linear: 1-1                            [1, 256]                  200,960\n",
       "├─Linear: 1-2                            [1, 128]                  32,896\n",
       "├─Linear: 1-3                            [1, 64]                   8,256\n",
       "├─Linear: 1-4                            [1, 10]                   650\n",
       "==========================================================================================\n",
       "Total params: 242,762\n",
       "Trainable params: 242,762\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.24\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.97\n",
       "Estimated Total Size (MB): 0.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [3-2] 커스텀 모델 클래스 구조 확인 -> torchinfo 활용\n",
    "# -------------------------------------------------------------------------------------\n",
    "# 모델 인스턴스 생성\n",
    "model = MNISTModel()\n",
    "print(model)\n",
    "\n",
    "# 모델 구조 출력\n",
    "summary(model, input_size=(1, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568e34a",
   "metadata": {},
   "source": [
    "[4] 학습 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9231372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# [4-1] 학습 설정\n",
    "# -------------------------------------------------------------------------------------\n",
    "# 학습 진행 횟수 및 학습량, 학습 진행 위치, W/b 업데이트 간격\n",
    "EPOCHS     = 1\n",
    "BATCH_SIZE = 200\n",
    "LR         = 0.01\n",
    "DEVICE     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# [4-2] 학습 인스턴스\n",
    "# -------------------------------------------------------------------------------------\n",
    "# Model 인스턴스 : 자동으로 층별 W, b 텐서 생성 및 랜덤 초기화\n",
    "loss_fn = nn.CrossEntropyLoss()  # softmax + log + NLLLoss 자동 적용\n",
    "                                  \n",
    "# 손실함수 인스턴스 : 다중분류용\n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 인스턴스 : 모델의 층별 파라미터 즉, W, b 업데이트\n",
    "optim = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 데이터로더 인스턴스 : 학습/검증/테스트에 사용될 학습량만큼 데이터 추출\n",
    "trainDL = DataLoader(trainDS, batch_size = BATCH_SIZE, shuffle=True)\n",
    "validDL = DataLoader(validDS, batch_size = BATCH_SIZE)\n",
    "testDL = DataLoader(testDS, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93126066",
   "metadata": {},
   "source": [
    "[5] 학습 진행 <HR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "770609dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util_func as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d70bed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH-000] TRAIN => Loss : 1.9693599     Acc : 0.75773\n",
      "            VALID => Loss : 0.3944545     Acc : 0.88450\n"
     ]
    }
   ],
   "source": [
    "# ---> 학습 진행\n",
    "# - 학습과 검증 결과 저장 : 학습 진행 / 중단 여부 결정, 모델 저장 여부\n",
    "TRAIN_LA = {\"loss\" : [], \"acc\" : []}\n",
    "VALID_LA = {\"loss\" : [], \"acc\" : []}\n",
    "\n",
    "# - 지정된 학습 횟수 만큼 학습 진행 & 에포크 단위로 학습과 검증 결과 저장\n",
    "for epoch in range(EPOCHS):\n",
    "    # 1에포크 학습\n",
    "    train_loss, train_acc = uf.train_one_epoch(model, trainDL, loss_fn, optim, DEVICE)\n",
    "\n",
    "    # 1에포크 학습 후 업데이트 W, b 검사 : 학습에 사용되지 않는 데이터\n",
    "    valid_loss, valid_acc = uf.evaluate(model, validDL, lossFn, DEVICE)\n",
    "\n",
    "    # 학습과 검증 결과 저장\n",
    "    TRAIN_LA[\"loss\"].append(train_loss)\n",
    "    TRAIN_LA[\"acc\"].append(train_acc)\n",
    "    VALID_LA[\"loss\"].append(valid_loss)\n",
    "    VALID_LA[\"acc\"].append(valid_acc)\n",
    "\n",
    "    # 진행 상황 출력\n",
    "    # [EPOCH-1] TRAIN => Loss : xxx     Acc : xxx       VALID => Loss : xxx     Acc : xxx\n",
    "    print(f\"[EPOCH-{epoch:03}] TRAIN => Loss : {train_loss:.7f}     Acc : {train_acc:.5f}\")\n",
    "    print(f'{\" \"*12}VALID => Loss : {valid_loss:.7f}     Acc : {valid_acc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
