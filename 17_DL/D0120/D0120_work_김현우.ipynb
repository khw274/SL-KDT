{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6a4a0b",
   "metadata": {},
   "source": [
    "### 【 D0120_work_김현우 】\n",
    "- 주__제 : 손글씨 데이터 분류\n",
    "- 데이터 : mnist_train.csv\n",
    "- 구__성 : 피쳐(hour) + 타겟(score)\n",
    "- 학__습 : 지도학습 + 회귀\n",
    "- 구__현 : 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9c2e5",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70ee45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, 5 to 0.617\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "# [1-1] 모듈 로딩\n",
    "import pandas as pd                 # 데이터 분석 및 처리용 모듈\n",
    "import torch                        # 텐서 및 수치, 기본 함수용 모듈\n",
    "import torch.nn as nn               # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F     # 인공신경망 함수(AF, LF, MF) 관련 모듈\n",
    "import torch.optim as optim         # 경사하강법 알고리즘으로 최적화 관련 모듈\n",
    "from torch.optim import Adam        # Adam 최적화 알고리즘\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# [1-2] 데이터 준비\n",
    "dataDF = pd.read_csv(\"../DATA/mnist_train.csv\")\n",
    "dataDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fd7273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTS : torch.Size([10000, 784]), yTS : torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# [1-3] 데이터 -> Tensor 변환\n",
    "# feature\n",
    "featureDF = dataDF[dataDF.columns[1:]]\n",
    "xTS = torch.tensor(featureDF.values/255, dtype=torch.float32)\n",
    "\n",
    "# target\n",
    "targetDF = dataDF[dataDF.columns[0:1]]\n",
    "yTS = torch.tensor(targetDF.values.flatten(), dtype=torch.long) \n",
    "\n",
    "print(f\"xTS : {xTS.shape}, yTS : {yTS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "배치 개수: 313\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = TensorDataset(xTS, yTS)\n",
    "print(len(dataset))  # 10000\n",
    "\n",
    "# DataLoader 생성 (배치 크기: 32, 셔플: True)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"배치 개수: {len(train_loader)}\")\n",
    "# 출력: 배치 개수: 313 (10000 / 32 = 312.5 → 313)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b0823",
   "metadata": {},
   "source": [
    "[2] 다중분류 모델 설계 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b571da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "#               입력수           퍼셉트론수/출력수           AF(활성화함수)\n",
    "# -------------------------------------------------------------------------------\n",
    "# 입력층           784                   784                \n",
    "# 은닉층1          784                   128                    ReLU\n",
    "# 은닉층2          128                    64                    ReLU\n",
    "# 은닉층3           64                    32                    ReLU\n",
    "# 출력층            32                    10                   Softmax  다중분류\n",
    "# -------------------------------------------------------------------------------\n",
    "# ★ Pytorch에는 입력층 클래스 존재 X -> 입력 텐서를 입력층으로 간주\n",
    "# -------------------------------------------------------------------------------\n",
    "class MultiClassModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hd1_layer = nn.Linear(784, 128)\n",
    "        self.hd2_layer = nn.Linear(128, 64)\n",
    "        self.hd3_layer = nn.Linear(64, 32)\n",
    "        self.out_layer = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.hd1_layer(x))\n",
    "        out = F.relu(self.hd2_layer(out))\n",
    "        out = F.relu(self.hd3_layer(out))\n",
    "        out = self.out_layer(out) # CrossEntropyLoss 안에 Softmax 내장\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8759c715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassModel(\n",
      "  (hd1_layer): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hd2_layer): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (hd3_layer): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (out_layer): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MultiClassModel()\n",
    "print(model)\n",
    "# summary(model, input_size=(1,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6531b",
   "metadata": {},
   "source": [
    "[3] 학습 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45bce28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3-1] 학습 설정\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "COUNT = int(xTS.shape[0] / BATCH_SIZE)\n",
    "\n",
    "# [3-2] 학습 인스턴스\n",
    "loss_fn = nn.CrossEntropyLoss() # softmax, log 자동 적용\n",
    "                                # softmax 는 모든 출력을 확률로 변환\n",
    "adam_opt = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b0c78",
   "metadata": {},
   "source": [
    "[4] 학습 진행<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2ebba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000_에포크] loss : 0.75851\n",
      "[005_에포크] loss : 0.10095\n",
      "[010_에포크] loss : 0.02573\n",
      "[015_에포크] loss : 0.02178\n",
      "[020_에포크] loss : 0.01391\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "for epoch in range(EPOCHS + 1):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for idx in range(COUNT):\n",
    "        # - 배치크기만큼 데이터 추출 인덱스\n",
    "        sIdx = idx * BATCH_SIZE\n",
    "        eIdx = sIdx + BATCH_SIZE\n",
    "        \n",
    "        # - 배치크기만큼 순전파 진행 ==> 예측값 추출\n",
    "        pre_y = model(xTS[sIdx:eIdx])\n",
    "\n",
    "        # - 손실계산\n",
    "        loss = loss_fn(pre_y, yTS[sIdx:eIdx])\n",
    "        \n",
    "        # - 역전파 + 최적화\n",
    "        adam_opt.zero_grad()\n",
    "        loss.backward()     ##<- 역전파: 경사하강법으로 W,b 계산진행\n",
    "        adam_opt.step()     ##<- 새로운 W,b 업데이트 진행\n",
    "        \n",
    "        # - 배치 크기 loss 누적\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 5 == 0:  \n",
    "        print(f'[{epoch:03d}_에포크] loss : {total_loss/COUNT:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32e2948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()  # 평가 모드 (드롭아웃, 배치정규화 비활성화)\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 안 함 (메모리 절약)\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            # 예측\n",
    "            predictions = model(x_batch)  # (batch, 10)\n",
    "            \n",
    "            # 가장 높은 점수의 클래스 선택\n",
    "            predicted_labels = torch.argmax(predictions, dim=1)  # (batch,)\n",
    "            \n",
    "            # 정답과 비교\n",
    "            correct = (predicted_labels == y_batch).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += y_batch.size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_samples * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ff9e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.63"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가 실행\n",
    "evaluate_model(model, train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
